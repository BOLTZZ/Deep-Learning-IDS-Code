{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing:"
      ],
      "metadata": {
        "id": "Cte-9yInNw9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the formatted dataset from a google drive.\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown https://drive.google.com/uc?id=1cvwrlIvVDWuJikwQPfSNBN_7x3Jpcpks "
      ],
      "metadata": {
        "id": "14Li7qShOBa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the csv file to a dataframe.\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"UNSW-NB15_data.csv\")"
      ],
      "metadata": {
        "id": "is-6K-Gx0ljj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the 'Unnamed: 0' (unessecary) and 'attack_cat' (this column maps 100% to the target column, so using it would not give us a generalizable model) columns:\n",
        "df = df.drop(labels = ['Unnamed: 0', 'attack_cat'], axis = 1)\n",
        "# Drop null values in the following columns (these colums have some null values):\n",
        "df = df.dropna(subset = ['ltime', 'sintpkt', 'dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'label'])"
      ],
      "metadata": {
        "id": "0LFGT9ky5Oi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical Features:"
      ],
      "metadata": {
        "id": "hstshLeXNxn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the testing and training data with normalization:"
      ],
      "metadata": {
        "id": "-G7aPw6V1FvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the testing/training data by normalizing the features using z-score normalization.\n",
        "from sklearn.model_selection import train_test_split\n",
        "numerical_features = ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'sload', 'dload', 'spkts', 'dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'sjit', 'djit', 'stime', 'ltime', 'sintpkt', 'dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm']\n",
        "df_numerical = df[numerical_features]\n",
        "df_numerical =(df_numerical - df_numerical.astype('float32').mean())/(df_numerical.astype('float32').std())\n",
        "y = df.label\n",
        "x = df_numerical\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "loJwbfmpCPsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a logistic regression model:"
      ],
      "metadata": {
        "id": "KRpIdE3tD7Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg_numerical = LogisticRegression(solver = 'lbfgs')\n",
        "log_reg_numerical.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "JuV_3gQ0D7dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the accuracy of this model.\n",
        "log_reg_numerical.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "RuUPVPoAD-5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = log_reg_numerical.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "IQOZDHMIEBN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a decision tree model:"
      ],
      "metadata": {
        "id": "sKIGU9JIEHgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree_numerical = DecisionTreeClassifier()\n",
        "decision_tree_numerical.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "c352WvO8EIak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the accuracy of decision tree model.\n",
        "decision_tree_numerical.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "dZBqSBcAELgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "y_pred = decision_tree_numerical.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "g_7nmt6yEL8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a random forest model of 70 trees:"
      ],
      "metadata": {
        "id": "7G-RNSAGENKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates random forest model.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_numerical = RandomForestClassifier(n_estimators = 70)\n",
        "random_forest_numerical.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "RzphSlmAEPI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets accuracy of random forest model.\n",
        "random_forest_numerical.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "yjZiOxC8ESYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "y_pred = random_forest_numerical.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "yuvmmaSjESza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorical Features:"
      ],
      "metadata": {
        "id": "SO9ZM6fpN1sF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the testing/training data with normalization nd binary encoding:"
      ],
      "metadata": {
        "id": "OJ3-sZxPDDp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing binary encoding on the categorical features.\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "categorical_features = ['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'service', 'ct_ftp_cmd']\n",
        "df_binary = df[categorical_features].join(df['label'])\n",
        "binary_encoder = ce.BinaryEncoder()\n",
        "df_binary = binary_encoder.fit_transform(df_binary)"
      ],
      "metadata": {
        "id": "xHfOCnI7DqRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features using z-score normalization.\n",
        "df_categorical = df_binary.drop(labels = 'label', axis = 1)\n",
        "df_categorical =(df_categorical - df_categorical.astype('float32').mean())/(df_categorical.astype('float32').std())\n",
        "y = df_binary.label\n",
        "x = df_categorical\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "5TfKnt7dHYvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a logistic regression model:"
      ],
      "metadata": {
        "id": "PXr_K7B1HgY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model.\n",
        "log_reg_categorical = LogisticRegression(solver = 'lbfgs')\n",
        "log_reg_categorical.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vFbhvO1XHc1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the accuracy of this model.\n",
        "log_reg_categorical.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "IHAc1wDiHjBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "y_pred = log_reg_categorical.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "kJoism2EHlbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a decison tree model:"
      ],
      "metadata": {
        "id": "ZVzGN9K1Hl2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model.\n",
        "decision_tree_categorical = DecisionTreeClassifier()\n",
        "decision_tree_categorical.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "4wgKHeAVHnW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the accuracy of decision tree model.\n",
        "decision_tree_categorical.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "CIqk213-Hpls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "y_pred = decision_tree_categorical.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "wUYlBFXRHq0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a random forest model of 70 trees:"
      ],
      "metadata": {
        "id": "zQgGMQ_9HsP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates random forest model.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_categorical = RandomForestClassifier(n_estimators = 70)\n",
        "random_forest_categorical.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2i9yzHZZHteY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets accuracy of random forest model.\n",
        "random_forest_categorical.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "tK0Esv9OHujd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "y_pred = random_forest_categorical.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "5dvFSAGpHvu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical and Categorical Features:"
      ],
      "metadata": {
        "id": "GfWkMRfEN3ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the testing/training data with normalization:"
      ],
      "metadata": {
        "id": "1e59y8lAI7TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the categorical features and numerical features together to create the final dataframe.\n",
        "df_numerical = df[numerical_features]\n",
        "df_final = df_numerical.join(df_binary)"
      ],
      "metadata": {
        "id": "7SpFUFVROCzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the training/testing data by normalizing the features using z-score normalization.\n",
        "df_both = df_final.drop(labels = 'label', axis = 1)\n",
        "df_both =(df_both - df_both.astype('float32').mean())/(df_both.astype('float32').std())\n",
        "y = df_final.label\n",
        "x = df_both\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "Spd58UbuJLdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the logistic regression model:"
      ],
      "metadata": {
        "id": "jxKkeKjwJgzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model.\n",
        "log_reg_final = LogisticRegression(solver = 'lbfgs')\n",
        "log_reg_final.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "mxJPSkaRJiRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the accuracy of this model.\n",
        "log_reg_final.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "tvkIqUloJkc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "y_pred = log_reg_final.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "Fg4DhXQ_JmNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the decision tree model:"
      ],
      "metadata": {
        "id": "30xmXsw_JnrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model.\n",
        "decision_tree_final = DecisionTreeClassifier()\n",
        "decision_tree_final.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vfp14ZRLJoxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the accuracy of decision tree model.\n",
        "decision_tree_final.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "WG-c-IF_JqHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "y_pred = decision_tree_final.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "L_NyF5Q1JrMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the random forest model using 70 trees:"
      ],
      "metadata": {
        "id": "mb82jnA0JscA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates random forest model.\n",
        "random_forest_final = RandomForestClassifier(n_estimators = 70)\n",
        "random_forest_final.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "RyVEaKCVJzte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets accuracy of random forest model.\n",
        "random_forest_final.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "XV8FAB8oJ06X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix.\n",
        "y_pred = random_forest_final.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "print(cm_df)"
      ],
      "metadata": {
        "id": "8V7046m_J1_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
