{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSWhZ9G-uZ0x"
      },
      "source": [
        "# Data Imports/Pre-Processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6euPJWsLUYn"
      },
      "outputs": [],
      "source": [
        "# Importing KYOTO-2006 data.\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown https://drive.google.com/uc?id=1-2p3ktXN6k23PFPL9w82psoRlgDBfU_N\n",
        "\n",
        "# Converting the csv file to dataframe.\n",
        "import pandas as pd\n",
        "kyoto = pd.read_csv('KYOTO_features.csv')\n",
        "kyoto = kyoto.drop(labels = 'Unnamed: 0', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8GTWL3cv43q"
      },
      "outputs": [],
      "source": [
        "# Importing UNSW-NB15 data.\n",
        "!gdown https://drive.google.com/uc?id=1-2GzNzitcNAkS8o3AjGt5s7ObExmc9wZ\n",
        "\n",
        "# Converting the csv file to dataframe.\n",
        "unsw = pd.read_csv('UNSW_features.csv')\n",
        "unsw = unsw.drop(labels = 'Unnamed: 0', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBhXB4hs2927"
      },
      "outputs": [],
      "source": [
        "# Converting the 'dsport' and 'sport' columns of UNSW-NB15 to numerical columns.\n",
        "\n",
        "# Converting the 'sport' column of UNSW-NB15.\n",
        "mask = unsw['sport'].apply(lambda x: type(x) == int or (type(x) == str and x.isnumeric()))\n",
        "\n",
        "unsw = unsw.loc[mask]\n",
        "unsw['sport'] = unsw['sport'].astype(int)\n",
        "\n",
        "# Converting the 'dsport' column of UNSW-NB15.\n",
        "mask = unsw['dsport'].apply(lambda x: type(x) == int or (type(x) == str and x.isnumeric()))\n",
        "\n",
        "unsw = unsw.loc[mask]\n",
        "unsw['dsport'] = unsw['dsport'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98n0ukzLz0wK"
      },
      "outputs": [],
      "source": [
        "# Performing label encoding on the categorical features of KYOTO-2006.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "categorical_features = ['Source_IP_addr', 'Dest_IP_addr', 'Protocol', 'service']\n",
        "for i in categorical_features:\n",
        "  label_encoder = LabelEncoder()\n",
        "\n",
        "  label_encoder.fit(kyoto[i])\n",
        "\n",
        "  kyoto[i] = label_encoder.transform(kyoto[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-PIhCvX0NoR"
      },
      "outputs": [],
      "source": [
        "# Performing label encoding on the categorical features of UNSW-NB15.\n",
        "categorical_features = ['dstip', 'service', 'proto', 'srcip']\n",
        "for x in categorical_features:\n",
        "  label_encoder = LabelEncoder()\n",
        "\n",
        "  label_encoder.fit(unsw[x])\n",
        "\n",
        "  unsw[x] = label_encoder.transform(unsw[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QdJpdjOSTh1"
      },
      "outputs": [],
      "source": [
        "# Dropping the null values of UNSW-NB15.\n",
        "unsw = unsw.dropna(subset=['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1or_1ij09jA"
      },
      "outputs": [],
      "source": [
        "# Creating testing/training data for KYOTO-2006.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "y = kyoto.Label\n",
        "x = kyoto.drop(labels = ['Label'], axis = 1)\n",
        "x = scaler.fit_transform(x)\n",
        "X_train_KYOTO, X_test_KYOTO, y_train_KYOTO, y_test_KOYTO = train_test_split(x, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlFy1HKa1NQ2"
      },
      "outputs": [],
      "source": [
        "# Creating testing/training data for UNSW-NB15.\n",
        "scaler = StandardScaler()\n",
        "y = unsw.label\n",
        "x = unsw.drop(labels = ['label'], axis = 1)\n",
        "x = scaler.fit_transform(x)\n",
        "X_train_UNSW, X_test_UNSW, y_train_UNSW, y_test_UNSW = train_test_split(x, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTT4GVQOLY8v"
      },
      "source": [
        "# Final Convolutional Neural Network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6V7yNubeCwZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the input shape.\n",
        "input_shape = (9,1)\n",
        "\n",
        "# Create a CNN with the different layers (Conv1D, MaxPooling, Dropout, and Dense).\n",
        "cnn = tf.keras.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv1D(32, kernel_size=1, activation='relu', input_shape=input_shape))\n",
        "cnn.add(tf.keras.layers.MaxPooling1D(pool_size=1))\n",
        "cnn.add(tf.keras.layers.Conv1D(64, kernel_size=1, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling1D(pool_size=1))\n",
        "cnn.add(tf.keras.layers.Conv1D(128, kernel_size=1, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling1D(pool_size=1))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.2))\n",
        "cnn.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Define the learning rate.\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define the optimizer.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Compile the model with binary crossentropy loss and the Adam optimizer.\n",
        "cnn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Get the initial weights of the architecture. \n",
        "initial_weights = cnn.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7d73LEGLdDY"
      },
      "outputs": [],
      "source": [
        "# Train the model on the UNSW-NB15 data.\n",
        "cnn.fit(X_train_UNSW, y_train_UNSW, batch_size=64, epochs=10)\n",
        "\n",
        "# Get the accuracy of the model on the test data.\n",
        "loss, accuracy = cnn.evaluate(X_test_UNSW, y_test_UNSW)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfit the model.\n",
        "cnn.set_weights(initial_weights)\n",
        "\n",
        "# Train the model on the KYOTO-2006 data.\n",
        "cnn.fit(X_train_KYOTO, y_train_KYOTO, batch_size=64, epochs=10)\n",
        "\n",
        "# Get the accuracy of the model on the test data.\n",
        "loss, accuracy = cnn.evaluate(X_test_KYOTO, y_test_KOYTO)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "N05Kv8Oax-9U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZQu0ajHJlxSf"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
